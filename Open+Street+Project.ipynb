{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# OpenStreetMap Case Study\n",
    "----\n",
    "Map Area:\n",
    "\n",
    "Greater London\n",
    "\n",
    "Link: https://mapzen.com/data/metro-extracts/your-extracts/c14328a6d43e\n",
    "\n",
    "I chose Greater London because my home city Beirut data is below 50 MB and I will be visiting London for the first time next week for a vacation with my wife :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems encountered in my map\n",
    "---\n",
    "After running sample of my data against data.py from the case study, I noticed the below problems:\n",
    "- Abbreviation of Saint to St in addr:Street\n",
    "- Tags with key 'fix me' to be ignored\n",
    "- Inconsistent Home numbers with comma and hyphens, convert comma to hyphen\n",
    "- In Wikipedia, remove additional character 'en:' from string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Fixing the St abbreviations in the key column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What I did here is I amended the update_name function we wrote earlier as below and fixed the regex formula\n",
    "# For example it change 137,139 to 137-139 which is consistent with the rest of the housenumber of multiple\n",
    "street_type_re = re.compile(r'^\\b\\S+\\.?', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Saint\"]\n",
    "\n",
    "mapping = { \"St\": \"Saint\",\n",
    "            \"st\": \"Saint\"}\n",
    "\n",
    "# I added the below inside my shape_element function\n",
    "if value[\"k\"] == 'addr:street':\n",
    "    # After searching inside the street names\n",
    "    m = ABBREVIATED_ST.search(value['v'])\n",
    "    # Run agaianst the regex\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type in mapping.keys():\n",
    "            # Run keys against the mapping dictionary identified above\n",
    "            node_way_tags['value'] = re.sub(ABBREVIATED_ST, mapping[m.group()], value['v'])\n",
    "            # Finally update any name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Dropping all tags with keys \"fixme\" as they are not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inside the data.py, I added the values fixme and FIXME to the keys to be ignored as I did with PROBLEMCHARS\n",
    "if PROBLEMCHARS.search(value['k']) or (value['k']) == 'fixme' or (value['k']) == 'FIXME': \n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inconsistent Home numbers with comma and hyphens, convert comma to hyphen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elif value[\"k\"] == 'addr:housenumber':\n",
    "            m = STREETNAMES.search(value['v'])\n",
    "            if m:\n",
    "                node_way_tags['value'] = re.sub(',', '-', value['v'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### In Wikipedia, remove additional character 'en:' from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If key is wikipedia, I cleaned the value of the string from 'en:'\n",
    "elif value[\"k\"] == 'wikipedia':\n",
    "            value_of_k = value['v']\n",
    "            node_way_tags['value'] = value_of_k[3:]\n",
    "            # Since it is fixed space I used index to slice it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting CSV tables to SQLITE Databse\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The below is copied from this post: \n",
    "# https://discussions.udacity.com/t/creating-db-file-from-csv-files-with-non-ascii-unicode-characters/174958/8\n",
    "# http://www.bogotobogo.com/python/python_sqlite_connect_create_drop_table.php\n",
    "\n",
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "mydb = 'greater_london.db'    # name of the sqlite database file\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(mydb)\n",
    "\n",
    "# Get a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "##############################################---NODES_TAGS---#########################################################\n",
    "\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes_tags''')\n",
    "conn.commit()\n",
    "\n",
    "# Create the nodes_tags table:\n",
    "cur.execute('''\n",
    "    CREATE TABLE nodes_tags (\n",
    "    id INTEGER,\n",
    "    key TEXT,\n",
    "    value TEXT,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES nodes(id))\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# Read in the csv file as a dictionary, format the\n",
    "# data as a list of tuples:\n",
    "with open('nodes_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"), i['type'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO nodes_tags(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "##############################################---WAYS_TAGS---##########################################################\n",
    "\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_tags''')\n",
    "conn.commit()\n",
    "\n",
    "# Create the table, specifying the column names and data types:\n",
    "cur.execute('''\n",
    "    CREATE TABLE ways_tags (\n",
    "    id INTEGER NOT NULL,\n",
    "    key TEXT NOT NULL,\n",
    "    value TEXT NOT NULL,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id))\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# Read in the csv file as a dictionary, format the\n",
    "# data as a list of tuples:\n",
    "with open('ways_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"), i['type'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO ways_tags(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "##############################################---NODES---##############################################################\n",
    "\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes''')\n",
    "conn.commit()\n",
    "\n",
    "# Create the table, specifying the column names and data types:\n",
    "cur.execute('''\n",
    "    CREATE TABLE nodes (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    lat REAL,\n",
    "    lon REAL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version INTEGER,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT)\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# Read in the csv file as a dictionary, format the\n",
    "# data as a list of tuples:\n",
    "with open('nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['version'].decode(\"utf-8\"), i['changeset'].decode(\"utf-8\"), i['timestamp'].decode(\"utf-8\"), i['user'].decode(\"utf-8\"), i['uid'].decode(\"utf-8\"), i['lat'].decode(\"utf-8\"), i['lon'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO nodes(id, version, changeset, timestamp, user, uid, lat, lon) VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "##############################################---WAYS---###############################################################\n",
    "\n",
    "cur.execute('''DROP TABLE IF EXISTS ways''')\n",
    "conn.commit()\n",
    "\n",
    "# Create the table, specifying the column names and data types:\n",
    "cur.execute('''\n",
    "    CREATE TABLE ways (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    \n",
    "    version TEXT,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT)\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# Read in the csv file as a dictionary, format the\n",
    "# data as a list of tuples:\n",
    "with open('ways.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['version'].decode(\"utf-8\"), i['changeset'].decode(\"utf-8\"), i['timestamp'].decode(\"utf-8\"), i['user'].decode(\"utf-8\"), i['uid'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO ways(id, version, changeset, timestamp, user, uid) VALUES (?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "##############################################---WAYS_NODES---#########################################################\n",
    "\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_nodes''')\n",
    "conn.commit()\n",
    "\n",
    "# Create the table, specifying the column names and data types:\n",
    "cur.execute('''\n",
    "    CREATE TABLE ways_nodes (\n",
    "    id INTEGER NOT NULL,\n",
    "    node_id INTEGER NOT NULL,\n",
    "    position INTEGER NOT NULL,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id),\n",
    "    FOREIGN KEY (node_id) REFERENCES nodes(id))\n",
    "''')\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# Read in the csv file as a dictionary, format the\n",
    "# data as a list of tuples:\n",
    "with open('ways_nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['node_id'].decode(\"utf-8\"), i['position'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO ways_nodes(id, node_id, position) VALUES (?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greater_london.osm ......... 52 MB\n",
      "greater_london.db .......... 29 MB\n",
      "nodes.csv ................... 16 MB\n",
      "ways.csv .................... 22 MB\n",
      "nodes_tags.csv .............. 38 MB\n",
      "ways_tags.csv ............... 4 MB\n",
      "ways_nodes.csv .............. 6 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "osm = os.path.getsize('greater_london.osm')/1000000\n",
    "mydb = os.path.getsize('greater_london.db')/1000000\n",
    "nodes_db = os.path.getsize('nodes.csv')/1000000\n",
    "ways_db = os.path.getsize('ways.csv')/100000\n",
    "nodes_tags_db = os.path.getsize('nodes_tags.csv')/100000\n",
    "ways_tags_db = os.path.getsize('ways_tags.csv')/1000000\n",
    "ways_nodes_db = os.path.getsize('ways_nodes.csv')/1000000\n",
    "\n",
    "print 'greater_london.osm .........', osm, 'MB'\n",
    "print 'greater_london.db ..........', mydb, 'MB'\n",
    "print 'nodes.csv ...................', nodes_db, 'MB'\n",
    "print 'ways.csv ....................', ways_db, 'MB'\n",
    "print 'nodes_tags.csv ..............', nodes_tags_db, 'MB'\n",
    "print 'ways_tags.csv ...............', ways_tags_db, 'MB'\n",
    "print 'ways_nodes.csv ..............', ways_nodes_db, 'MB'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1940,)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT COUNT(DISTINCT(e.uid))\\\n",
    "            FROM (SELECT uid FROM nodes\\\n",
    "            UNION ALL SELECT uid FROM ways) e')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(197114,)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT count(*)\\\n",
    "            FROM nodes')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(37393,)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT count(*)\\\n",
    "            FROM ways')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique node tags types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(468,)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT COUNT(DISTINCT(key))\\\n",
    "            FROM nodes_tags')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique node tags types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(563,)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT COUNT(DISTINCT(key))\\\n",
    "            FROM ways_tags')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique number of types of Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT value\\\n",
    "            FROM nodes_tags\\\n",
    "            WHERE key = \"amenity\"\\\n",
    "            GROUP BY value')\n",
    "len(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Amenities in nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicycle_parking: 507\n",
      "bench: 466\n",
      "restaurant: 368\n",
      "post_box: 298\n",
      "telephone: 290\n",
      "cafe: 270\n",
      "waste_basket: 248\n",
      "pub: 166\n",
      "fast_food: 151\n",
      "atm: 103\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT value, count(value) AS Counter\\\n",
    "            FROM nodes_tags\\\n",
    "            WHERE key = \"amenity\"\\\n",
    "            GROUP BY value\\\n",
    "            ORDER BY Counter DESC\\\n",
    "            LIMIT 10')\n",
    "g = cur.fetchall()\n",
    "for key, value in g:\n",
    "    print('{}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Amenities in ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'parking', 270),\n",
       " (u'restaurant', 225),\n",
       " (u'cafe', 167),\n",
       " (u'pub', 136),\n",
       " (u'school', 126),\n",
       " (u'place_of_worship', 114),\n",
       " (u'fast_food', 91),\n",
       " (u'bank', 35),\n",
       " (u'bar', 31),\n",
       " (u'community_centre', 27)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT value, count(value) AS Counter\\\n",
    "            FROM ways_tags\\\n",
    "            WHERE key = \"amenity\"\\\n",
    "            GROUP BY value\\\n",
    "            ORDER BY Counter DESC\\\n",
    "            LIMIT 10')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historic categories and numbers available in Greater London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archaeological_site: 2\n",
      "blue_plaque: 4\n",
      "cannon: 2\n",
      "castle: 14\n",
      "citywalls: 3\n",
      "fence: 1\n",
      "footway: 1\n",
      "icon: 1\n",
      "industrial: 1\n",
      "memorial: 79\n",
      "monastery: 1\n",
      "monument: 13\n",
      "police_telephone: 1\n",
      "relic: 1\n",
      "retaining_wall: 4\n",
      "roman_road: 22\n",
      "ruins: 4\n",
      "ship: 2\n",
      "yes: 3\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT s.value, COUNT(s.value)\\\n",
    "            FROM \\\n",
    "            (SELECT key, value FROM nodes_tags UNION ALL SELECT key, value FROM ways_tags) AS s\\\n",
    "            WHERE key = \"historic\"\\\n",
    "            GROUP BY s.value')\n",
    "g = cur.fetchall()\n",
    "for key, value in g:\n",
    "    print('{}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Top 10 contributing users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom Chance: 23100\n",
      "Paul The Archivist: 16674\n",
      "Amaroussi: 13199\n",
      "Ed Avis: 12128\n",
      "Derick Rethans: 10707\n",
      "abc26324: 9941\n",
      "peregrination: 8529\n",
      "Harry Wood: 7314\n",
      "ecatmur: 6361\n",
      "moyogo: 5543\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT s.user, count(s.user) as Counter\\\n",
    "            FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) AS s\\\n",
    "            GROUP BY s.user\\\n",
    "            ORDER BY Counter DESC\\\n",
    "            LIMIT 10')\n",
    "g = cur.fetchall()\n",
    "for key, value in g:\n",
    "    print('{}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(234507,)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of entries recorded in this database\n",
    "cur.execute('SELECT SUM(counter)\\\n",
    "            FROM\\\n",
    "            (SELECT s.user, count(s.user) as Counter\\\n",
    "            FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) AS s\\\n",
    "            GROUP BY s.user\\\n",
    "            ORDER BY Counter DESC) AS t')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(113496,)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of entries recorded in this database from top 10 contributers\n",
    "cur.execute('SELECT SUM(counter)\\\n",
    "            FROM\\\n",
    "            (SELECT s.user, count(s.user) as Counter\\\n",
    "            FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) AS s\\\n",
    "            GROUP BY s.user\\\n",
    "            ORDER BY Counter DESC\\\n",
    "            LIMIT 10) AS t')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1940,)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT COUNT(DISTINCT(s.uid))\\\n",
    "            FROM\\\n",
    "            (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) AS s')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclution on this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking the above data and knowing that we have \n",
    "- Total entries 234,507 entries\n",
    "- 113,496 of 234,507 are from the top 10 contributers which is almost 50% of the entries\n",
    "From the total number of users:\n",
    "- 10 are contributing 50% of data\n",
    "- 1930 are contributing the resulting 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Additional Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### After queiying the data, I noticed lots of new issues which I was initmidated to neglect but couldn't, among these issues that didn't show at the beginnning of wrangling this data set was the below 2 issues:\n",
    "\n",
    "1. I can see lots of \"randomjunk_bot\" in keys which I need to drop from my datasets.\n",
    "2. I can see that there is a lot of \"en\" in keys which causes the key to be useless\n",
    "\n",
    "## Here is how I fixed both new issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1:\n",
    "Remove records with this key \"randomjunk_bot\",\n",
    "As I did before I added this to my python script next to the above to drop if the key has this exact value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all keys with these values as they are useless and will contaminate the data\n",
    "        if PROBLEMCHARS.search(value['k']) or (value['k']) == 'fixme' or (value['k']) == 'FIXME' or (value['k']) == 'randomjunk_bot':\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2:\n",
    "Replace \"en\" in key with the proper value after it and get the type to be regular. An example is \"species:en\" where the \"en\" becomes the key and species becomes the \"type\" which is not consistent with this type of data where species shall be the key with type regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whenever the key is valued as en, replace it with the value in type and put type regular \n",
    "if node_way_tags['key'] == 'en':\n",
    "    node_way_tags['key'] = node_way_tags['type']\n",
    "    node_way_tags['type'] = 'regular'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of unique species available in Greater London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(326,)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT COUNT(DISTINCT(value))\\\n",
    "            FROM nodes_tags\\\n",
    "            WHERE key = \"species\"')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues that can be improved\n",
    "Looking at the data for building, we can notice that below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(19379,)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of entries with type building\n",
    "cur.execute('SELECT count(value)\\\n",
    "            FROM ways_tags\\\n",
    "            WHERE key = \"building\"')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETON_PLACE: 1\n",
      "AIR_SHAFT: 14\n",
      "APARTMENTS: 1077\n",
      "BANDSTAND: 2\n",
      "BLOCK: 5\n",
      "BOAT: 1\n",
      "BRIDGE: 1\n",
      "BUS_GARAGE: 1\n",
      "CASTLE: 13\n",
      "CHAPEL: 1\n",
      "CHIMNEY: 1\n",
      "CHURCH: 34\n",
      "CIVIC: 1\n",
      "CLOCK_TOWER: 1\n",
      "CLUBHOUSE: 1\n",
      "COLLEGE: 4\n",
      "COMMERCIAL: 219\n",
      "CONSTRUCTION: 9\n",
      "CONVENT: 1\n",
      "COUNCIL_FLATS: 3\n",
      "DATA_CENTER: 3\n",
      "DEPOT: 1\n",
      "DORMITORY: 1\n",
      "FACADE: 1\n",
      "FACULTY: 4\n",
      "FARM: 1\n",
      "FARM_AUXILIARY: 1\n",
      "FERRY_TERMINAL: 1\n",
      "FLATS: 24\n",
      "GALLERY: 1\n",
      "GARAGE: 39\n",
      "GARAGES: 42\n",
      "GASOMETER: 2\n",
      "GRANDSTAND: 1\n",
      "GREENHOUSE: 3\n",
      "HALL_OF_RESIDENCE: 1\n",
      "HOSPITAL: 12\n",
      "HOTEL: 15\n",
      "HOUSE: 3511\n",
      "HOUSES: 2\n",
      "HUT: 6\n",
      "INDUSTRIAL: 69\n",
      "KINDERGARTEN: 1\n",
      "KIOSK: 1\n",
      "LIGHT_INDUSTRIAL: 1\n",
      "MOSQUE: 1\n",
      "MULTIPLE: 1\n",
      "NO: 14\n",
      "OFFICE: 77\n",
      "OFFICES: 3\n",
      "OUTBUILDING: 23\n",
      "PART: 12\n",
      "PAVILION: 1\n",
      "PLACE_OF_WORSHIP: 1\n",
      "PORTACABIN: 1\n",
      "PRISON: 1\n",
      "PUB: 3\n",
      "PUBLIC: 7\n",
      "RESIDENTIAL: 1342\n",
      "RETAIL: 228\n",
      "ROOF: 37\n",
      "SCHOOL: 70\n",
      "SEMIDETACHED_HOUSE: 2\n",
      "SERVICE: 1\n",
      "SHED: 11\n",
      "SHIP: 2\n",
      "SHOP: 7\n",
      "STADIUM: 1\n",
      "STATION: 16\n",
      "STUDENT_ACCOMODATION: 1\n",
      "STUDENT_RESIDENCE: 1\n",
      "SUBSTATION: 1\n",
      "TERRACE: 361\n",
      "TOWER: 6\n",
      "TRAIN_STATION: 14\n",
      "TUNNEL_ENTRANCE: 1\n",
      "TUNNEL_SHAFT: 1\n",
      "UNIVERSITY: 24\n",
      "UTILITY: 1\n",
      "VIADUCT: 7\n",
      "VILLAGE_HALL: 1\n",
      "WAREHOUSE: 3\n",
      "YES: 11961\n"
     ]
    }
   ],
   "source": [
    "# Types of building with counter\n",
    "cur.execute('SELECT value, COUNT(value)\\\n",
    "            FROM ways_tags\\\n",
    "            WHERE key = \"building\"\\\n",
    "            GROUP BY value')\n",
    "g = cur.fetchall()\n",
    "for key, value in g:\n",
    "    print('{}: {}'.format(key.upper(), value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have 19,379 entries with key building, but if we look closer we will notice that out of these records,  11,961 (almost 60%) are labeled \"yes\" which is good but not good enough knowing that the data can be more specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An improvement that can be made here is be more specific on the type of the building especially for tourists who might want to know if this building is a hotel or residential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I believe this is easier said than done, but looking above we notice that the majority of the constibuters on this dataset are less than maybe 30 users, for that we can use a rewarding system that might reward them points for their contributions on this issue and other issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional issues I want to investigate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most popular type of shops in Greater London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clothes: 152\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT s.value, COUNT(*) as counter \\\n",
    "            FROM nodes_tags AS s \\\n",
    "            JOIN (SELECT DISTINCT(id) FROM nodes_tags) AS t \\\n",
    "            ON s.id = t.id \\\n",
    "            WHERE s.key=\"shop\" \\\n",
    "            GROUP BY s.value \\\n",
    "            ORDER BY counter DESC \\\n",
    "            LIMIT 1')\n",
    "g = cur.fetchall()\n",
    "for key, value in g:\n",
    "    print('{}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 type of shops in Greater London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLOTHES: 152\n",
      "CONVENIENCE: 151\n",
      "HAIRDRESSER: 78\n",
      "SUPERMARKET: 45\n",
      "ESTATE_AGENT: 42\n",
      "JEWELRY: 33\n",
      "BEAUTY: 31\n",
      "DRY_CLEANING: 31\n",
      "NEWSAGENT: 31\n",
      "FURNITURE: 29\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT s.value, COUNT(*) as counter \\\n",
    "            FROM nodes_tags AS s \\\n",
    "            JOIN (SELECT DISTINCT(id) FROM nodes_tags) AS t \\\n",
    "            ON s.id = t.id \\\n",
    "            WHERE s.key=\"shop\" \\\n",
    "            GROUP BY s.value \\\n",
    "            ORDER BY counter DESC \\\n",
    "            LIMIT 10')\n",
    "g = cur.fetchall()\n",
    "for key, value in g:\n",
    "    print('{}: {}'.format(key.upper(), value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the results, the data looks logical knowing that Greater London is renowned for its shopping experience and due to being the most expensive real estate in EU, having estate agent shops makes sense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
